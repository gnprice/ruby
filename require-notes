2012-09-01 (starting notes, long after started work)

Big allocations in requiring an empty file.
Total of 10 4099-byte allocations, and one 8192-byte.
That's 49182 bytes; there are 2500 or so bytes in <KiB allocs.

  8192 (but then this isn't repeated on subsequent iterations)
  #2  vm_xmalloc (objspace=0x80274dd8, size=<optimized out>) at gc.c:831
  #3  0x800381d8 in io_binwrite (str=2151403120, 
      ptr=0x803f1548 "{:ALLOCATE_INCREASE=>2469944}", len=29, fptr=0x802ee5f8, 
      nosync=1) at io.c:1127
  #4  0x80038514 in io_fwrite (nosync=1, fptr=0x802ee5f8, str=<optimized out>)
      at io.c:1257
  #5  io_write (io=<optimized out>, str=<optimized out>, nosync=1) at io.c:1294
  #6  0x80043f9e in rb_p (obj=2151403260) at io.c:6715
  #7  0x80043ff9 in rb_f_p (argc=1, argv=0xb78d9034, self=2150265340) at io.c:6749
  #8  0x80133866 in call_cfunc (func=0x80043fc0 <rb_f_p>, recv=2150265340, len=-1, 
      argc=1, argv=0xb78d9034) at vm_insnhelper.c:343
  #9  0x8014316b in vm_call_cfunc (me=0x802eafd8, blockptr=0x0, recv=<optimized out>, 
      num=1, reg_cfp=0xb7958f68, th=0xb78d9038) at vm_insnhelper.c:431
  [...]

  4099 x9 (which is the length of the load path)
  #2  vm_xmalloc (objspace=0x80274dd8, size=<optimized out>) at gc.c:831
  #3  0x800e19ae in str_new (klass=2150263800, ptr=0x0, len=4098) at string.c:395
  #4  0x800e3cb7 in rb_str_new (len=4098, ptr=0x0) at string.c:417
  #5  rb_usascii_str_new (ptr=0x0, len=4098) at string.c:418
  #6  0x801a83c5 in rb_file_expand_path (fname=<optimized out>, dname=4)
      at file.c:3244
  #7  0x801a03bd in rb_get_expanded_load_path () at load.c:46
  #8  0x801a06fd in rb_feature_p (feature=0x803bcdec "isolated/1", ext=0x0, rb=0, 
      expanded=0, fn=0xbfffe6ac) at load.c:160
  #9  0x801a0fc0 in search_required (safe_level=0, path=0xbfffe6a4, fname=2151402980)
      at load.c:568
  #10 rb_require_safe (fname=2151402980, safe=0) at load.c:628
  #11 0x8013383c in call_cfunc (func=0x801a1610 <rb_f_require>, recv=2150265340, 
      len=1, argc=1, argv=0xb78d9050) at vm_insnhelper.c:349
  #12 0x8014316b in vm_call_cfunc (me=0x803edae0, blockptr=0x0, recv=<optimized out>, 
      num=1, reg_cfp=0xb7958f40, th=0xb78d9054) at vm_insnhelper.c:431

  4099
  #2  vm_xmalloc (objspace=0x80274dd8, size=<optimized out>) at gc.c:831
  #3  0x800e19ae in str_new (klass=0, ptr=0x0, len=4098) at string.c:395
  #4  0x800e6f73 in rb_str_tmp_new (len=4098) at string.c:770
  #5  0x801a96f3 in rb_find_file_ext_safe (filep=0xbfffe6a8, ext=0x80262420, 
      safe_level=0) at file.c:5247
  #6  0x801a0ff0 in search_required (safe_level=0, path=0xbfffe6a4, fname=2151402980)
      at load.c:573
  #7  rb_require_safe (fname=2151402980, safe=0) at load.c:628
  #8  0x8013383c in call_cfunc (func=0x801a1610 <rb_f_require>, recv=2150265340, 
      len=1, argc=1, argv=0xb78d9050) at vm_insnhelper.c:349
  #9  0x8014316b in vm_call_cfunc (me=0x803edae0, blockptr=0x0, recv=<optimized out>, 
      num=1, reg_cfp=0xb7958f40, th=0xb78d9054) at vm_insnhelper.c:431

  8192
  #2  vm_xmalloc (objspace=0x80274dd8, size=<optimized out>) at gc.c:831
  #3  0x800308e2 in io_fillbuf (fptr=0x803fc990) at io.c:1557
  #4  0x8003904e in rb_io_getline_fast (io=2151402420, enc=0x80277868, 
      fptr=0x803fc990) at io.c:2788
  #5  rb_io_getline_1 (rs=2150241400, limit=-1, io=2151402420) at io.c:2873
  #6  0x8003c117 in rb_io_gets (io=2151402420) at io.c:2977
  #7  0x800643f3 in lex_io_gets (parser=0x803fc8d0, io=2151402420) at parse.y:5489
  #8  0x800808f6 in lex_getline (parser=0x803fc8d0) at parse.y:5419
  #9  parser_nextc (parser=0x803fc8d0) at parse.y:5571
  #10 parser_prepare (parser=0x803fc8d0) at parse.y:6747
  #11 yycompile0 (arg=2151663824, tracing=0) at parse.y:5351
  #12 0x8014b80b in thread_suppress_tracing (th=0x80274b70, ev=1, 
      func=0x80080620 <yycompile0>, arg=2151663824, always=1) at thread.c:4519
  #13 0x80155925 in ruby_suppress_tracing (func=0x80080620 <yycompile0>, 
      arg=2151663824, always=1) at thread.c:4495
  #14 0x8006b7c3 in yycompile (line=1, 
      f=0x803fc898 "/home/greg/src/ruby-require-torture/isolated/1.rb", 
      parser=0x803fc8d0) at parse.y:5382
  #15 rb_parser_compile_file (vparser=2151402440, 
      f=0x803fc898 "/home/greg/src/ruby-require-torture/isolated/1.rb", 
      file=2151402420, start=1) at parse.y:5512
  #16 0x800cc79f in load_file_internal (arg=3221218416) at ruby.c:1641
  #17 0x8001a369 in rb_ensure (b_proc=0x800cc2e0 <load_file_internal>, 
      data1=3221218416, e_proc=0x800ca270 <restore_lineno>, data2=1) at eval.c:821
  #18 0x800cdd33 in load_file (opt=0xbfffe418, script=0, fname=2151402460, 
      parser=<optimized out>) at ruby.c:1678
  #19 rb_load_file (
      fname=0x803fc7b0 "/home/greg/src/ruby-require-torture/isolated/1.rb")
      at ruby.c:1687
  #20 0x8019fb0d in rb_load_internal (fname=2151402540, wrap=0) at load.c:306
  #21 0x801a130b in rb_require_safe (fname=2151402980, safe=0) at load.c:636
  #22 0x8013383c in call_cfunc (func=0x801a1610 <rb_f_require>, recv=2150265340, 
      len=1, argc=1, argv=0xb78d9050) at vm_insnhelper.c:349
  #23 0x8014316b in vm_call_cfunc (me=0x803edae0, blockptr=0x0, recv=<optimized out>, 
      num=1, reg_cfp=0xb7958f40, th=0xb78d9054) at vm_insnhelper.c:431

(and then on to the same with "isolated/2")

Fixed the nine allocations for load_path entries with another
snapshot-protected cache.


Now it turns out that the sequence
  a = []; b = []; (1..1000).each {|i| a << i; b.replace a; b.replace [] }
causes a realloc on each '<<'.  The reason is that when an array is made
shared, we forget its capacity, because the shared-root array reuses the
'capa' field to store its refcount.

So, in normal usage we don't want the real loaded_features array to be made shared.
(Short of fixing that issue.)

So let's have three values:
  loaded_features  // the real internal structure
  loaded_features_exported  // what we've given the user
  loaded_features_snapshot  // what we gave the user

In normal usage these are
  A   nil  nil
After an export, they are
  A    A'  nil

... urgh, no, that won't do.  Consider code like this:
  f = $LOADED_FEATURES
  # ... lots of stuff ...
  puts "There are #{f.size} features loaded.\n"
I don't want to change semantics to break that, so after that
early $LOADED_FEATURES query we have to keep the array it returned,
i.e. 'f', matching our internal data structure.  And I don't want
to just abandon this case for the optimization -- so I want to be fast
even while keeping that match.

Short of some other clever hack, I think that means I need to expose
the internal data structure, and snapshot it as I currently do.  So
let's fix the array code so that's efficient.


09-03

Todo after fast-require-v0.7.3:
 . remove print (oops)
 . freeze the load_path too
 . run tests
 * write some tests, probably
 . backport to 1.9.2-p290
 x figure out stupid RVM
 . time our app
.* time my benchmark systematically,
   at various stages of the patchset
.* write message
 * submit


09-07

RVM is dumb, so trying to work without it.

time ./configure --prefix /home/greg/lib/ruby-1.9.2-p290 && time make -j12 ruby && time make -j12 && time make -j12 install
...

prefix=~/lib/ruby-1.9.2-p290 && time PATH=$prefix/bin:$PATH gem install bundler && time PATH=$prefix/bin:$PATH bundle install

# I don't understand the bug this works around, but it does
sed -i 's/#<Syck::DefaultKey:[^>]*>/=/' $prefix/lib/ruby/gems/1.9.1/specifications/*

# Nor this
ln -s /usr/lib/i386-linux-gnu/libcurl.so.4 $prefix/lib/libcurl.so


09-08

Huh.  A puzzling installation failure I was seeing last night seems to
be related to my commit 3d119ea "Optimize modifying a no-longer-shared array".
Here's the bisection command line:

v=$(git rev-parse HEAD); prefix=~/lib/ruby-$(git describe --tags HEAD); time { git checkout $v && git clean -fxd && autoconf && ./configure --prefix=$prefix && make -j12 ruby && make -j12 install-nodoc && ls -l $prefix/lib/ruby/1.9.1/; } 2>&1 | tee /tmp/log.$(git describe --tags HEAD); ls $prefix/lib/ruby/1.9.1/rubygems.rb

(NB this is with install-nodoc, to avoid the doc-building issue.)

Oh, odder:
$ prefix=~/lib/ruby-1.9.2-p290-take4 && time PATH=$prefix/bin:$PATH gem install bundler
<internal:lib/rubygems/custom_require>:29:in `require': no such file to load -- etc (LoadError)
That prefix was installed with 'make install-nodoc'.

Also with -take5, installed with 'make install'.  Now I wonder how my original ~/lib/ruby-1.9.2-p290 worked.
v=v1_9_2_290; prefix=~/lib/ruby-1.9.2-p290-take5; time { git checkout $v && git clean -fxd && autoconf && ./configure --prefix=$prefix && make -j12 ruby && make -j12 install && ls -l $prefix/lib/ruby/1.9.1/; } 2>&1 | tee /tmp/log.$v; alert

... And this works.
v=v1_9_2_290; prefix=~/lib/ruby-1.9.2-p290-take6; time { git checkout $v && git clean -fxd && autoconf && ./configure --prefix=$prefix && make -j12 ruby && make -j12 && make -j12 install && ls -l $prefix/lib/ruby/1.9.1/; } 2>&1 | tee /tmp/log.$v; alert

Well.  Let's face the doc-building issue.

OK, 'git bisect run make -j12' says it's that same commit 3d119ea.

And, splitting that into little pieces and doing another bisect
fingers the change that actually optimizes in the
ARY_SHARED_NUM(shared) == 1 case, where I've made that the last change
in the series (after adding the shared_num field and using it.)
And, that change causes the failure all on its own, without shared_num.

Probably there's some case where we miscount shared_num.  That logic
has a smell to it.  In particular, I suspect there is a case where we
turn an array that other code actually knows about into a shared_root
array, and then don't increment shared_num for itself.  Or something.



SHARED ARRAYS
=============

The condition that rb_ary_modify checks (and takes action only if
true) is ARY_SHARED_P; which checks the ELTS_SHARED flag; which is set
(in array.c) just in FL_SET_SHARED and unset in FL_UNSET_SHARED; of
which the former is called just in rb_ary_set_shared and
ary_make_shared.  So when our optimization breaks a share,
  * ary came through one of those two functions (and has not already
    been unshared); and
  * ARY_SHARED_NUM(ARY_SHARED(ary)) == 1.
When that is a problem, either
  * something has a reference to ARY_SHARED(ary) as an array, or
  * something has an array ary2 with ARY_SHARED(ary2) == ARY_SHARED(ary), or
  * something I'm not thinking of.



09-09

Oh, and why is expanding the load path so slow?  strace says it's not
going and lstat'ing all those path components -- it's not trying to
resolve symlinks or even make sure the directories exist.  The code
(rb_file_expand_path_internal() in file.c) is a mess -- 341 lines, 152
even after unifdef'ing the DOS extra-mess, full of ad-hoc
locals-munging macros, virtually uncommented -- but it appears to
 * do tilde-expansion;
 * prefix non-absolute paths with the cwd;
 * normalize .., ., and repeated /.
No syscalls, except possibly as a result of allocation or getpwnam().

So this really is slow just because the allocation drives the garbage collector.



09-15

Not really working on this at the moment (rather on my PyCon talk proposal),
but here's a nice account of the benchmark suite the Rubinius folks made:
  http://fwiw.heroku.com/articles/2011/05/26/rubiniuss-benchmark-suite/
Should try it out -- hopefully one of them exercises 'require'.



10-11

Hello again.  Benchmarking.

tm () { label="$1"; shift; for i in {1..5}; do { time "$@"; } 2>&1; done | perl -lne 'BEGIN { @r = () }; if (/^real\s*(.*)/) { $_ = $1; s/^0m// or die "Big time"; s/s$//; push @r, $_; }; END { my @rs = sort @r; print ("'"$label"' $rs[0] | ".join(" ", @r)) }'; }

git checkout $COMMIT && git clean -fxd && autoreconf && ./configure --prefix ~/lib/ruby-$(git describe --tags --always) && make && make -j12 install

v=v1_9_2_290-8-g3d119ea; n=16000; tm $v ~/lib/ruby-$v/bin/ruby -I ../ruby-require-torture -e n=$n'; (1..n).each {|i| require "isolated/#{i}"}'


10-12

Recording links from long ago.  Didn't I write these down before?  I
can't find where I did.

Xavier Shay's original blog post:
  http://rhnh.net/2011/05/28/speeding-up-rails-startup-time
and pull request:
https://github.com/ruby/ruby/pull/25
and the ticket he worked in (which conflates several issues --
  as reported in 2010 it's about lots of stats, but then it becomes
  code review hour for Xavier's efforts):
http://bugs.ruby-lang.org/issues/3924

Peter Cooper's writeup after Masaya Tarui's tweak:
http://www.rubyinside.com/ruby-1-9-3-faster-loading-times-require-4927.html


Early discussion of the $LOAD_PATH issue, way back in January 2011:
  http://scoop.simplyexcited.co.uk/2011/03/14/rails-3-benchmarks-startup-time/
(quoting Yehuda Katz from rails-core in January.)

Discussion of trying to cache expanded LOAD_PATH, in 2012:
  https://bugs.ruby-lang.org/issues/5767
  https://github.com/ruby/ruby/pull/68/files
Hadn't seen that before.  This one is 303 lines and adds a number
of methods to load_path's singleton class.  Mine is 88 lines.
(My LOADED_FEATURES index is more code, 216 of which 23 are
shared with the LOAD_PATH cache.  All numbers are sums of
per-commit shortstats.)  Also this doesn't handle mutating the
strings themselves, AFAICT.  OTOH it invalidates if the cwd
or the filesystem_encoding change, which I probably should do too.

Oh, and that is one of the "falcon" patches -- the poster is
Yura Sokolov aka funny_falcon.  All four are described at
  https://gist.github.com/1688857
Another one is also 'require'-related -- that's
  https://github.com/ruby/ruby/pull/66
which keeps $LOADED_FEATURES as a sorted list.  This one also
munges the singleton class, and doesn't handle mutation of strings.
It is a little shorter than mine, at 178 lines.


Here are articles about the upcoming releases, by Peter Cooper:
  http://www.rubyinside.com/ruby-2-0-implementation-work-begins-what-is-ruby-2-0-and-whats-new-5515.html
  http://www.rubyinside.com/ruby-2-0-release-schedule-announced-roll-on-2013-5536.html
The latter says "October 2012: Feature freeze", so I hope I'm not too late.


Ruby 1.9.4 doesn't seem to exist anymore as a concept.  Here's the
best detailed discussion I found:
  http://bugs.ruby-lang.org/issues/5056
but it ends in 2011-08 with no conclusion.  (Bonus: Lucas Nussbaum,
the Debian maintainer for Ruby, trying and failing to get them to
make their release/maintenance practices sane.)  Now there is no
v1_9_4 branch, and I can't target my bug report for 1.9.4.


10-27

Hey-hey, people looked at my patches!

Patches 1-3, including the $LOADED_FEATURES index, have been smiled
upon and have received no criticism yet.  Patch 4, the
expanded-$LOAD_PATH cache, people have pointed out ought to invalidate
on chdir, and someone has gone and tried doing that (with too much
code.)  Also, Yura / funny_falcon pointed out it should invalidate on
change of filesystem encoding.  OK, that's a small incremental bit of
code too, but yuck.  How many other things like that might there be?

Let's trace the code and attempt an inventory of mutable state that
affects the validity of the $LOAD_PATH cache.  We force the elements
of $LOAD_PATH themselves to be frozen strings, fortunately.

We're caching the result of
  rb_file_expand_path_fast(fname, Qnil);
where fname is $LOAD_PATH[i].to_str.  OK, that's
  check_expand_path_args(fname, Qnil);
  return rb_file_expand_path_internal(fname, Qnil, 0, 0, EXPAND_PATH_BUFFER());
The first line there reduces to
  rb_get_path(fname)
which is
  rb_get_path_check(fname, rb_safe_level());
... urgh, so there's probably our first mutable state:
  #1. rb_safe_level(), aka GET_THREAD()->safe_level.
Then rb_get_path_check() begins with (where obj is fname)
  if (insecure_obj_p(obj, level))
    rb_insecure_operation();
... so if OBJ_TAINTED(obj) gets set, we could call that.
It raises an exception.
  #2. OBJ_TAINTED({$LOAD_PATH[i].to_str})
Then
    CONST_ID(to_path, "to_path");
    tmp = rb_check_funcall(obj, to_path, 0, 0);
Well, that at least we don't have to worry about... unless someone
can set to_path on these frozen strings' singletons.  Hmm.
  #3. $LOAD_PATH[i].to_str.to_path

The next step is
  tmp = file_path_convert(obj);
which in particular, if !defined(_WIN32), depends on
  rb_filesystem_encoding() != rb_enc_from_index(ENCODING_GET(obj));
and if so (and some other conditions) does
  return rb_str_conv_enc(obj, fname_encoding, fs_encoding);
where the latter arguments are the two sides of that inequality.
So
  #4. rb_enc_from_index(ENCODING_GET({$LOAD_PATH[i].to_str}));
  #4'. rb_default_internal_encoding() != NULL (spotted this one later)
  #5. rb_filesystem_encoding()
Then if two executions match to this point, I believe they do through
the end of check_expand_path_args().

Next, rb_file_expand_path_internal(fname, Qnil, 0, 0, EXPAND_PATH_BUFFER()).
This is a long function.  We have again
  rb_filesystem_encoding();
  rb_enc_get(fname);
  OBJ_TAINTED(fname);
which are covered above.  Then if s[0] == '~' where s = StringValuePtr(fname),
  rb_home_dir(buf, result)
so
  #6. getenv("HOME") if fname starts with ~/ or == '~'
  #7. getpwnam(user) if fname matches %r<^~(?<user>[^/]+)(/|$)>
Ifdef DOSISH_DRIVE_LETTER, and has_drive_letter(s), and !isdirsep(s[2]),
then we have a path with specified drive but not a full path, and we
may actually call rb_file_expand_path_internal() recursively.  Oh wait!
No, because dname is nil.  Phew.  Well, we still depend on
  #8. getcwdofdrv(*s)
If this is not an absolute path, we depend on my_getcwd().
(What's wrong with everyone else's getcwd()?  I don't know.)
Depending on various defines, that can be const ".", or
  #9. getcwd() or getwd()

Then there's a whole bunch more garbage, mostly to do with Windows.
Most of it looks pure, but I'm not sure about
  #10. cygwin_conv_path(CCP_POSIX_TO_WIN_A | CCP_RELATIVE, path, w32buf, bufsize);
   and cygwin_conv_to_win32_path(path, w32buf)
  #11. FindFirstFileW(wstr, &wfd);

Oh goodness, and that's all (all of rb_file_expand_path_internal()) under
#ifndef _WIN32.  There's another similarly long implementation in win32/file.c.
That one depends on
  #12. home_dir() if starts with ~
  #13. GetFullPathNameW(), which perhaps (I don't know) depends on cwd



OK, so
  #1. rb_safe_level(), aka GET_THREAD()->safe_level.
  #2. OBJ_TAINTED({$LOAD_PATH[i].to_str})
  #3. $LOAD_PATH[i].to_str.to_path
  #4. rb_enc_from_index(ENCODING_GET({$LOAD_PATH[i].to_str}));
  #4'. rb_default_internal_encoding() != NULL
  #5. rb_filesystem_encoding()
  #6. getenv("HOME") if fname starts with ~/ or == '~'
  #7. getpwnam(user) if fname matches %r<^~(?<user>[^/]+)(/|$)>
  #8. getcwdofdrv(*s)
  #9. getcwd() or getwd()
  #10. cygwin_conv_path(CCP_POSIX_TO_WIN_A | CCP_RELATIVE, path, w32buf, bufsize);
  #11. FindFirstFileW(wstr, &wfd);
  #12. home_dir() if starts with ~
  #13. GetFullPathNameW(), which perhaps (I don't know) depends on cwd
If we say screw Windows, and forget people who muck with the path strings we
have so carefully frozen, we're left with
  #1. rb_safe_level(), aka GET_THREAD()->safe_level.
  #4'. rb_default_internal_encoding() != NULL
  #5. rb_filesystem_encoding()
  #6. getenv("HOME") if fname starts with ~/ or == '~'
  #7. getpwnam(user) if fname matches %r<^~(?<user>[^/]+)(/|$)>
  #9. getcwd() or getwd()
I'm comfortable throwing out the rest of those, too, other than
  [well, now that I see #4', it's clearly in the same rank as #5]
  #5. rb_filesystem_encoding()
  #9. getcwd() or getwd()
So that's good.  Though I'm not sure I want to so glibly say screw Windows.

Hmm, and what is the impact of either the filesystem encoding changing
or the cwd changing?  What does it do to the expansion of $LOAD_PATH
and to how the $LOADED_FEATURES lookup then behaves?  (Because that affects
just how unpleasant it is to not do the same for Windows.)

Well, for the later lookups to correctly match "#{load_path_element}#{feature}"
against "#{loaded_feature}", we'll need load_path_element and loaded_feature
to be in the same encoding.  We do the comparison bytewise, so if they're in
different encodings it will be totally wrong.

But where do the $LOADED_FEATURES entries come from?  Will they not
get left behind if the filesystem encoding changes?  So we'll have
entries there in the old encoding, and we'll convert $LOAD_PATH
entries to the new encoding when expanding them, so they'll be
compared wrong and generally fail to match.  In conclusion, anyone who
changes the filesystem encoding after interpreter startup / after any
encoding-sensitive entries make it into either $LOAD_PATH or
$LOADED_FEATURES deserves what they get.

It'd be cool to demonstrate that, against trunk and/or 1.9.3-p194.

Yes, in fact entries are added to $LOADED_FEATURES by
rb_provide_feature() only; this is called by rb_provide(), which
forces its argument to usascii (does that mean it must be really
ASCII, or does it mean binary? (*)), and by rb_require_safe() after
loading a file; in the latter case the argument is supplied by
search_required(), which uses rb_filesystem_str_new_cstr(),
which... gee, that's complicated, but it makes the string, calls
rb_enc_associate() with the filesystem encoding, and then calls
rb_str_conv_enc() from the filesystem encoding to the default
internal encoding.

(*) It means binary, but the string will be labeled as US-ASCII if
it's all 7-bit.  See rb_external_str_new_with_enc()... err, no, this
uses a different codepath.  This uses rb_usascii_str_new_cstr(), which
apparently takes the bytes literally, labels them as US-ASCII, and
sets the ENC_CODERANGE_7BIT flag.  Nothing seems to check that they
actually are 7-bit.

OK, so on reading rb_str_conv_enc_opts() (which implements
rb_str_conv_enc()), what that means is that
rb_filesystem_str_new_cstr() takes its bytestring input, interprets it
as characters per the filesystem encoding, and returns that string
with the bytes prescribed by the internal encoding and so labeled.

So... $LOAD_PATH expansion converts the path entries into the
filesystem encoding, and those are the bytes we use in
loaded_feature_path().  But the bytes of the 'name' passed to
loaded_feature_path() are in the *internal* encoding.  This is messed
up even if the encoding settings don't get changed after startup.

How to demo?  Let's see:
 - set internal different from external/filesystem; say UTF-8 and ISO-8859-1
 - put something nontrivial in $LOAD_PATH
 - require something from there; something that prints on load
 - require it again; it should get loaded again
Hmm.
  $ ruby -Iniño  -e 'Encoding.default_internal = Encoding.find("ISO-8859-1"); require "boy"; require "boy"'
  boy
So it's not as totally broken as I thought.

Running out of tuits for the night (10-28.)  Will have to study more later.

Hmm.  (So much for running out of tuits.)  With some debugging output added:
  $LOADED_FEATURES[10]: enc UTF-8: /home/greg/src/ruby-require-torture/encoding/niño/boy.rb
  expanded_load_path[0]: enc UTF-8: /home/greg/src/ruby-require-torture/encoding/niño
So expansion is not doing what I think.
Oh, oh, the issue is that I need to actually set the internal encoding.
Otherwise it doesn't do any conversion.  Make that #4' above.

Trying that, I get
  expanded_load_path[0]: enc ISO-8859-1: /home/greg/src/ruby-require-torture/encoding/ni�o
as hoped for.  But now it can't find the file to load, spoiling the demo;
probably because the actual filename in the filesystem is the UTF-8 bytes
of that string.

Now trying the reverse, so the external encoding matches the filename I
actually created.
  $ ruby -I ~/src/ruby-require-torture/encoding/niño -e 'puts "A"; $stdout.flush; Encoding.default_internal = Encoding.find("ISO-8859-1"); puts "B"; $stdout.flush; Encoding.default_external = Encoding.find("UTF-8"); puts "C"; $stdout.flush; require "boy"; puts "D"; $stdout.flush; require "boy"' 2>&1 | tail -2
  $LOADED_FEATURES[10]: enc UTF-8: /home/greg/src/ruby-require-torture/encoding/niño/boy.rb
  expanded_load_path[0]: enc UTF-8: /home/greg/src/ruby-require-torture/encoding/niño
Why is the $LOADED_FEATURES entry in UTF-8?  Hmm... in fact the conversion
I saw in search_required() happens only in some paths, which appear to be when
we are right in the middle of loading the file already.  Otherwise it comes from
rb_find_file_safe() or rb_find_file_ext_safe().  Which appear to return strings
in filesystem encoding.  And indeed when I set default_external, I start accumulating
$LOADED_FEATURES entries in the new encoding.

Got it.
  $ ruby -I ~/src/ruby-require-torture/encoding/niño -e 'Encoding.default_internal = Encoding.find("UTF-8"); require "boy"; Encoding.default_external = Encoding.find("ISO-8859-1"); require "boy"' 2>/dev/null
  boy
  strange-boy
Here 'strange-boy' is what I put in .../$'ni\xf1o'/boy.rb, which is the
ISO-8859-1 encoding of the path.  So if we change filesystem
encodings, we will misunderstand and effectively (except in even odder
circumstances) forget old entries in $LOADED_FEATURES, and end up
re-loading the files -- rather, trying to, and ending up at new paths.

So yes, anyone who does that deserves what they get.

Now, what about chdir?


10-31

I've come to the opinion that anyone who changes any of these after
the interpreter starts, and relies on $LOAD_PATH's interaction with
$LOADED_FEATURES, deserves whatever they get.  The current behavior is
already impossible to defend in that case.  And none of these even
make sense to change after interpreter startup in the first place
other than the cwd.

Now the Ruby people don't see that -- in particular Masaya Tarui, the
core guy who committed the hack optimization last year and seems to be
the main reviewer on this change, is actually interested in the case
when *home directories* change.

Home directories.  Change.  You know, because someone ran 'usermod' or
something.  I've never even dealt with a system where a home directory
*ever* changes, over decades, after it's assigned.  I guess if you
have some really awkward volume-provisioning system you could find
yourself needing to change from /home/vol1/$USER to /home/vol2/$USER
or the like.  But surely nobody in their right mind tries to keep any
of that user's processes running before and after the change.

I can only infer he's just blindly following the existing code's logic
(though seems not to have been as systematic as I -- this is just #6
and #7 of 14 items in my analysis above) without thinking through what
it means.

Here he is:

  rb_file_expand_path_fast depends on not only current working
  directory but also home directories too.  it uses ENV["HOME"] and
  getpwnam (normally). [...]

  we have some choice. 
  1) support both ENV and getpwnam.
  2) support only ENV.
  3) no support home dirs change.
  4) accept  (G1)~(G3)  and reject others.
  5) reject this ticket :-(

  what do you think about this issue?
  in my mind,  4 > 1 = 2 >>>>>>> 5 > 3 

I appreciate that 5 is after a >>>>>>>, but 3 is my pick.

Anyway, Hiroshi Shirosaki is on it -- he's got patches that tarui
(username, aka taru-san in a previous comment by another Japanese guy)
wants him to commit, on top of mine, with just one more change.  So I
think I will stand back for now, in the interest of getting my fixes
in.  Maybe I will come back after it's all done, provide a patch with
a fat negative diffstat, and try to convince them they can let go of
this particular bit of bug-compatibility with themselves (on a release
numbered 2.0, for heaven's sake!)


11-16

Notes on the blog post:

  Possible directions:
   - go deeply into how I profiled, spotted slow bits, etc
     (mention compiling with -pg!) (mention rbenv, etc)
   - go into what's still slow, why the GC is slow
   - go deeply into workings of 'require' and my patch
     (probably less interesting? less generalizable, usable)
  Also, surely show before-and-after profiles.

  ---

  Two possible takes:
   - Profiler shows it's the GC; now profile the GC;
     this is what I actually did, right?  with stack and all, right?
   - This time it's not the same in benchmark and in app;
     so study app; gee, that's a mess; and...

  Hmm.  What I actually did was a little complicated -- I added my own
  instrumentation to gc.c, and then to get stack traces I attached gdb
  and set breakpoints on the instrumentation.  (See my 'gc-profile'
  branch.)  Not hard, but complicated to pack into this post.  Maybe I
  should... end the post here with the observation that the GC is the
  issue, and promise to follow up with a post about tackling that.  And
  then before that post, do some work to package up what I did for easy
  reuse?  Maybe delay that post to... after the Pivotal talk would be
  excellent, if that turns out to be soon, or otherwise after Boston.RB,
  and announce and describe the tool there.  Doing so at a talk means I
  get an opportunity for feedback from representative members of my
  audience before the public announcement.

  One way to package it up that could be pretty nice is as an option to
  perf that gathers things up appropriately.  E.g.,
  --blackbox=function[,function...], to mean to treat that function as a
  black box, meaning truncate the call stack at any point where it's
  called.  Then --blackbox=garbage_collect would do nicely.


2013-02-14

Looking at 2.0.0-rc2 to confirm my fixes are effective in it.  Taking
recipe from 10-11 with some tweaks.

tm () { label="$1"; shift; for i in {1..5}; do { time "$@"; } 2>&1; done | perl -lne 'BEGIN { @r = () }; if (/^real\s*(.*)/) { $_ = $1; s/^0m// or die "Big time"; s/s$//; push @r, $_; }; END { my @rs = sort @r; print ("'"$label"' $rs[0] | ".join(" ", @r)) }'; }

# This now makes rubyx explicit (clean -fxd is dangerous!)
# and adds a symlink for rbenv.
COMMIT=...
time { cd ~/src/rubyx && git fetch && git checkout $COMMIT && NAME=$(git describe --tags --always) && git clean -fxd && autoreconf && ./configure --prefix ~/lib/ruby-$NAME && make -j12 && make install && ln -s ~/lib/ruby-$NAME ~/.rbenv/versions/$NAME; }

# This now uses rbenv; more amenable to tab-completion on the version.
rbenv shell v2_0_0_rc2; n=16000; tm $(rbenv version-name) ruby -I ../ruby-require-torture -e n=$n'; (1..n).each {|i| require "isolated/#{i}"}'


Results:

n=16000
v2_0_0_rc2 3.821 | 4.547 3.884 3.837 3.821 3.972
v1_9_3_194 10.010 | 9.945 10.096 10.022 9.994 10.010
v1_9_3_194-fast-require-v0.8.2part2 2.661 | 2.767 2.791 2.684 2.661 2.673

Hrm.  Not a fluke:
v2_0_0_rc2 3.918 | 6.045 4.036 4.055 3.921 3.918

Urgh, trying to compare app startup, 'bundle install' says:
  Bundler is not compatible with Ruby 2.0 or Rubygems 2.0.
  Please upgrade to Bundler 1.3 or higher.
